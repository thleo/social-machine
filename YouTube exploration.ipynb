{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube exploration\n",
    "### [Source](https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection)\n",
    "\n",
    "***\n",
    "#### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:25:24) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version check\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick note on `nltk.stopwords()`\n",
    "*for first time nltk users*\n",
    "\n",
    "In order to use this package, you have to install the `stopwords` package from the `nltk` download GUI.  \n",
    "This can be achieved by entering the following into python console:\n",
    "```python\n",
    ">>> import nltk\n",
    ">>> nltk.download()\n",
    "```\n",
    "\n",
    "Then the GUI will pop up, go to the corpus tab and find `stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LZQPQhLyRh9-wNRtlZDM90f1k0BrdVdJyN_YsaSwfxc</td>\n",
       "      <td>Jason Haddad</td>\n",
       "      <td>2013-11-26T02:55:11</td>\n",
       "      <td>Hey, check out my new website!! This site is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>z13lfzdo5vmdi1cm123te5uz2mqig1brz04</td>\n",
       "      <td>ferleck ferles</td>\n",
       "      <td>2013-11-27T21:39:24</td>\n",
       "      <td>Subscribe to my channel ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>z122wfnzgt30fhubn04cdn3xfx2mxzngsl40k</td>\n",
       "      <td>Bob Kanowski</td>\n",
       "      <td>2013-11-28T12:33:27</td>\n",
       "      <td>i turned it on mute as soon is i came on i jus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>z13ttt1jcraqexk2o234ghbgzxymz1zzi04</td>\n",
       "      <td>Cony</td>\n",
       "      <td>2013-11-28T16:01:47</td>\n",
       "      <td>You should check my channel for Funny VIDEOS!!﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>z12avveb4xqiirsix04chxviiljryduwxg0</td>\n",
       "      <td>BeBe Burkey</td>\n",
       "      <td>2013-11-28T16:30:13</td>\n",
       "      <td>and u should.d check my channel and tell me wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "5  LZQPQhLyRh9-wNRtlZDM90f1k0BrdVdJyN_YsaSwfxc      Jason Haddad   \n",
       "6          z13lfzdo5vmdi1cm123te5uz2mqig1brz04    ferleck ferles   \n",
       "7        z122wfnzgt30fhubn04cdn3xfx2mxzngsl40k      Bob Kanowski   \n",
       "8          z13ttt1jcraqexk2o234ghbgzxymz1zzi04              Cony   \n",
       "9          z12avveb4xqiirsix04chxviiljryduwxg0       BeBe Burkey   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "5  2013-11-26T02:55:11  Hey, check out my new website!! This site is a...   \n",
       "6  2013-11-27T21:39:24                          Subscribe to my channel ﻿   \n",
       "7  2013-11-28T12:33:27  i turned it on mute as soon is i came on i jus...   \n",
       "8  2013-11-28T16:01:47    You should check my channel for Funny VIDEOS!!﻿   \n",
       "9  2013-11-28T16:30:13  and u should.d check my channel and tell me wh...   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "5      1  \n",
       "6      1  \n",
       "7      0  \n",
       "8      1  \n",
       "9      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psy_data = 'data/Youtube01-Psy.csv'\n",
    "df_psy = pd.read_csv(psy_data)\n",
    "df_psy.head(10)\n",
    "# class: boolean for spam tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordlist(slist):\n",
    "    l = []\n",
    "    for s in slist: # access each comment\n",
    "        x = re.sub(\"[^a-zA-Z]\",\" \", s) # replace punctuation with whitespace\n",
    "        l.append(x) # big list of cleaned comments\n",
    "    lower = [s.lower() for s in l] # still list of long strings\n",
    "    en_stopwords = set(stopwords.words(\"english\"))\n",
    "    words = [s.split() for s in lower for w in s if not w in en_stops] \n",
    "    # words is a giant list of lists of words in any given comment, minus stopwords\n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shouldn', 'ma', 'his', 'yourselves', 'is', 'again', 'whom', 'off', 'our', 'has', 'couldn', 'no', 'other', 'until', 'be', 'under', 'didn', 'as', 'wasn', 'aren', 'through', 'had', 'in', 'ain', 'hadn', 'ourselves', 'over', 'by', 'about', 'so', 'more', 'o', 'should', 'after', 'what', 'on', 'for', 'there', 'haven', 'itself', 'him', 'during', 'now', 're', 'mustn', 'them', 'yours', 'ours', 'before', 'here', 'why', 't', 'those', 've', 'needn', 'me', 'doesn', 'any', 'shan', 'too', 'most', 'a', 'will', 'he', 'with', 'out', 'they', 'where', 'very', 'while', 'or', 'some', 'won', 'i', 'these', 'herself', 'having', 'from', 'being', 'an', 'which', 'above', 'are', 'all', 'only', 'who', 'that', 'between', 'against', 'your', 'y', 'not', 'and', 'my', 'you', 'weren', 'once', 'the', 'nor', 'll', 'yourself', 's', 'just', 'am', 'it', 'to', 'doing', 'when', 'same', 'hasn', 'further', 'mightn', 'if', 'do', 'did', 'down', 'she', 'this', 'how', 'both', 'don', 'we', 'such', 'at', 'was', 'been', 'd', 'than', 'can', 'does', 'myself', 'm', 'were', 'into', 'her', 'hers', 'its', 'below', 'but', 'of', 'because', 'their', 'own', 'wouldn', 'theirs', 'have', 'few', 'themselves', 'then', 'each', 'up', 'isn', 'himself'}\n",
      "yes\n",
      "['apple', 'banana']\n"
     ]
    }
   ],
   "source": [
    "en_stops = set(stopwords.words(\"english\"))\n",
    "print(en_stops)\n",
    "if 'ma' in en_stops:\n",
    "    print('yes')\n",
    "testing = ['apple', 'banana', 'his']    \n",
    "testing = [t for t in testing if not t in en_stops]\n",
    "print(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['huh', 'anyway', 'check', 'out', 'this', 'you', 'tube', 'channel', 'kobyoshi'], ['huh', 'anyway', 'check', 'out', 'this', 'you', 'tube', 'channel', 'kobyoshi'], ['huh', 'anyway', 'check', 'out', 'this', 'you', 'tube', 'channel', 'kobyoshi'], ['huh', 'anyway', 'check', 'out', 'this', 'you', 'tube', 'channel', 'kobyoshi'], ['huh', 'anyway', 'check', 'out', 'this', 'you', 'tube', 'channel', 'kobyoshi']]\n"
     ]
    }
   ],
   "source": [
    "print(com_words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words in list:  728812\n",
      "Unique words:  1353\n"
     ]
    }
   ],
   "source": [
    "com_list = list(df_psy['CONTENT'])\n",
    "\n",
    "com_words = wordlist(com_list) # separates comments into lists of strings\n",
    "\n",
    "all_words= []\n",
    "\n",
    "for i in com_words:\n",
    "    for j in i:\n",
    "        all_words.append(j)\n",
    "words_only = list(all_words)        \n",
    "print(\"All words in list: \",len(all_words))        \n",
    "all_words = list(set(all_words))\n",
    "print(\"Unique words: \",len(all_words))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['huh', 'anyway'] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['buy', 'hacked', 'whats', 'singers', 'say', 'model', 'brew', 'itunes', 'divertenti', 'ago']\n"
     ]
    }
   ],
   "source": [
    "# to see current items, run below\n",
    "print(words_only[:2],'\\n'*5)\n",
    "print(all_words[:10]) # contains unique words only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 6, 4, 7, 8, 8, 8, 8, 3] \n",
      " {3, 4, 5, 6, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "# basic example of how lists work\n",
    "l1 = [5,5,5,6,4,7,8,8,8,8,3]\n",
    "s1 = set(l1)\n",
    "\n",
    "print(l1, '\\n', s1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
